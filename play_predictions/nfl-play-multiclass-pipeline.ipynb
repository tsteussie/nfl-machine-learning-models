{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore',category=ImportWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import randint, loguniform\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingRandomSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:00:17.517320Z",
     "start_time": "2023-12-25T06:00:14.799100Z"
    }
   },
   "id": "774348c602e5ca1e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Train test split parameters\n",
    "test_holdout_percentage = 0.25\n",
    "\n",
    "# Leave One Out Encoder Sigma value - 0.04 is the top performing value.\n",
    "sigma = 0.05                                                        # Tested parameters: 0.04, 0.05, 0.10, 0.30, 0.60\n",
    "\n",
    "# Feature scaler\n",
    "feature_scaler = StandardScaler()                                   # Tested parameters: MinMaxScaler(), StandardScaler(), MaxAbsScaler(), RobustScaler()\n",
    "\n",
    "# HalvingRandomSearchCV parameters\n",
    "scoring = 'f1_weighted'\n",
    "n_cross_validation = 3\n",
    "\n",
    "# Specify the HalvingRandomSearchCV parameters\n",
    "halving_parameter = 2.0\n",
    "max_resource = 1000\n",
    "resource_divisor = 2.0\n",
    "min_resource = int(round((max_resource / resource_divisor), 0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:00:17.529084Z",
     "start_time": "2023-12-25T06:00:17.522004Z"
    }
   },
   "id": "39c59abc33e5e515"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create timer to calculate total workbook time in hours\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:00:17.531552Z",
     "start_time": "2023-12-25T06:00:17.526892Z"
    }
   },
   "id": "5dc8446203dc414e"
  },
  {
   "cell_type": "markdown",
   "id": "c4f8e047",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IMPORT PROCESSED NFL-DATA-PY CSV FILE\n",
    "##### https://pypi.org/project/nfl-data-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "(58083, 156)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import csv file from nfl-data-py\n",
    "df = pd.read_csv(r'/Users/ttas2/Documents/Python/nfl-machine-learning-models/output_files/nfl_post_processing_multiclass_play_classification_data.csv')\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:21.759422Z",
     "start_time": "2023-12-25T06:06:19.753650Z"
    }
   },
   "id": "f8d686327dce3e32"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print columns with missing values\n",
    "print(df.columns[df.isnull().any()].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:21.811677Z",
     "start_time": "2023-12-25T06:06:21.751042Z"
    }
   },
   "id": "629bc39586b0fba6"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "       week posteam posteam_type defteam  yardline_100   \n1237      4     ARI         away      SF          75.0  \\\n28838    12      KC         away      LV          36.0   \n\n       quarter_seconds_remaining  half_seconds_remaining   \n1237                         862                     862  \\\n28838                        600                     600   \n\n       game_seconds_remaining  game_half  qtr  ...   \n1237                      862          2    4  ...  \\\n28838                    2400          1    2  ...   \n\n       remain_yds_prod_def_dl_count  remain_yds_div_def_db_count   \n1237                      13.333333                     0.833333  \\\n28838                     13.333333                     0.666667   \n\n       remain_yds_prod_def_db_count  remain_yds_div_score_diff   \n1237                      13.333333                   8.030303  \\\n28838                     16.666667                   8.412698   \n\n       remain_yds_prod_score_diff  run_ratio_off_priors  run_ratio_def_priors   \n1237                     1.383648              0.424928              0.338324  \\\n28838                    1.320755              0.356758              0.455181   \n\n       posteam_season  defteam_season  play_type  \n1237         ari_2023         sf_2023    outside  \n28838         kc_2023         lv_2023      short  \n\n[2 rows x 156 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>posteam</th>\n      <th>posteam_type</th>\n      <th>defteam</th>\n      <th>yardline_100</th>\n      <th>quarter_seconds_remaining</th>\n      <th>half_seconds_remaining</th>\n      <th>game_seconds_remaining</th>\n      <th>game_half</th>\n      <th>qtr</th>\n      <th>...</th>\n      <th>remain_yds_prod_def_dl_count</th>\n      <th>remain_yds_div_def_db_count</th>\n      <th>remain_yds_prod_def_db_count</th>\n      <th>remain_yds_div_score_diff</th>\n      <th>remain_yds_prod_score_diff</th>\n      <th>run_ratio_off_priors</th>\n      <th>run_ratio_def_priors</th>\n      <th>posteam_season</th>\n      <th>defteam_season</th>\n      <th>play_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1237</th>\n      <td>4</td>\n      <td>ARI</td>\n      <td>away</td>\n      <td>SF</td>\n      <td>75.0</td>\n      <td>862</td>\n      <td>862</td>\n      <td>862</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>13.333333</td>\n      <td>0.833333</td>\n      <td>13.333333</td>\n      <td>8.030303</td>\n      <td>1.383648</td>\n      <td>0.424928</td>\n      <td>0.338324</td>\n      <td>ari_2023</td>\n      <td>sf_2023</td>\n      <td>outside</td>\n    </tr>\n    <tr>\n      <th>28838</th>\n      <td>12</td>\n      <td>KC</td>\n      <td>away</td>\n      <td>LV</td>\n      <td>36.0</td>\n      <td>600</td>\n      <td>600</td>\n      <td>2400</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>13.333333</td>\n      <td>0.666667</td>\n      <td>16.666667</td>\n      <td>8.412698</td>\n      <td>1.320755</td>\n      <td>0.356758</td>\n      <td>0.455181</td>\n      <td>kc_2023</td>\n      <td>lv_2023</td>\n      <td>short</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 156 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert binary columns to integers\n",
    "binary_columns = df.columns[df.isin([0,1]).all()].tolist()\n",
    "df[binary_columns] = df[binary_columns].apply(pd.to_numeric, downcast='integer', errors='coerce', axis=1)\n",
    "\n",
    "df.sample(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:37.267977Z",
     "start_time": "2023-12-25T06:06:22.189287Z"
    }
   },
   "id": "41f7422bcc2cf003"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c9bcb28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:37.281655Z",
     "start_time": "2023-12-25T06:06:37.267924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "play_type\nshort      0.409070\ninside     0.217534\noutside    0.202125\ndeep       0.171272\nName: proportion, dtype: float64"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target frequency\n",
    "target_count = df.play_type.value_counts(normalize=True)\n",
    "\n",
    "target_count"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAIN TEST SPLIT\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c140526b778c182"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c674bc94c9111c14",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:37.411923Z",
     "start_time": "2023-12-25T06:06:37.287783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    outside\n1     inside\n2      short\nName: play_type, dtype: object"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into target and feature datasets\n",
    "X, y = df.loc[:, df.columns != 'play_type'], df['play_type']\n",
    "\n",
    "initial_features = X.columns.to_list()\n",
    "\n",
    "# Print target labels\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert target labels to integers\n",
    "y = le.fit_transform(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:37.412660Z",
     "start_time": "2023-12-25T06:06:37.345335Z"
    }
   },
   "id": "272836dfb3c918fa"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "# Create train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_holdout_percentage, random_state=67)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:37.494010Z",
     "start_time": "2023-12-25T06:06:37.352315Z"
    }
   },
   "id": "4943bbf5"
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd4c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BASELINE MODEL\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28e9513e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:37.496033Z",
     "start_time": "2023-12-25T06:06:37.465146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline f1 score: 24.1%\n"
     ]
    }
   ],
   "source": [
    "# Create and fit baseline model to compare performance\n",
    "baseline_model = DummyClassifier(strategy='most_frequent', random_state=67)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate model accuracy on test data\n",
    "y_baseline_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print(f\"Baseline f1 score: {round(f1_score(y_test,y_baseline_pred, average='weighted')*100, 1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL PIPELINE\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html\n",
    "##### https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html\n",
    "##### https://imbalanced-learn.org/stable/references/over_sampling.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
    "##### https://xgboost.readthedocs.io/en/stable/parameter.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28eb7c49ea06b6d2"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordinal features: 4 : ['game_half', 'qtr', 'down', 'remaining_downs']\n",
      " \n",
      "boolean features: 66 : ['goal_to_go', 'shotgun', 'no_huddle', 'div_game', 'report_eligible', 'dtg_99to90', 'dtg_89to60', 'dtg_59to45', 'dtg_44to35', 'dtg_34to21', 'dtg_20to10', 'dtg_09to00', 'prev1_big_play_pass', 'prev2_big_play_pass', 'prev3_big_play_pass', 'prev1_big_play_run', 'prev2_big_play_run', 'prev3_big_play_run', 'prev1_negative_pass', 'prev2_negative_pass', 'prev3_negative_pass', 'prev1_negative_run', 'prev2_negative_run', 'prev3_negative_run', 'prev1_play_off_penalty', 'prev1_play_def_penalty', 'prev2_play_off_penalty', 'prev2_play_def_penalty', 'prev3_play_off_penalty', 'prev3_play_def_penalty', 'prev1_play_run_outside', 'prev1_play_run_inside', 'prev1_play_pass_deep', 'prev1_play_pass_short', 'prev2_play_run_outside', 'prev2_play_run_inside', 'prev2_play_pass_deep', 'prev2_play_pass_short', 'prev3_play_run_outside', 'prev3_play_run_inside', 'prev3_play_pass_deep', 'prev3_play_pass_short', 'prev1_incomplete_pass', 'prev2_incomplete_pass', 'prev3_incomplete_pass', 'prev4_incomplete_pass', 'prev1_shotgun', 'prev2_shotgun', 'prev3_shotgun', 'prev1_qb_hit', 'prev2_qb_hit', 'prev3_qb_hit', 'prev1_no_huddle', 'prev2_no_huddle', 'prev3_no_huddle', 'prev1_first_down_pass', 'prev2_first_down_pass', 'prev3_first_down_pass', 'prev1_first_down_run', 'prev2_first_down_run', 'prev3_first_down_run', 'prev1_effct_play', 'prev2_effct_play', 'prev3_effct_play', 'two_min_warning', 'posteam_side']\n",
      " \n",
      "numeric features: 69 : ['quarter_seconds_remaining', 'remain_yds_prod_def_dl_count', 'off_wr_count', 'off_te_count', 'prev3_yards_gained', 'remain_yds_prod_score_diff', 'n_offense', 'off_rb_count', 'off_ol_count', 'ol_to_dl_ratio', 'no_score_prob', 'defteam_timeouts_remaining', 'hb_to_lb_ratio', 'n_defense', 'total_line', 'prev3_wpa', 'game_humidity', 'remain_yds_div_def_db_count', 'game_wind_prod_game_temp', 'score_differential', 'game_temp', 'game_seconds_remaining', 'safety_prob', 'drive_play_count', 'score_differential_norm', 'remaining_yards_per_down', 'ep_game_sec_ratio', 'run_ratio_def_priors', 'yardline_100', 'posteam_score', 'prev2_yards_gained', 'wp', 'game_temp_prod_game_humidity', 'run_ratio_off_priors', 'remain_yds_div_def_dl_count', 'play_sequence_game', 'ydstogo', 'remain_yds_prod_off_hb_count', 'spread_line', 'game_temp_div_game_humidity', 'remain_yds_prod_def_db_count', 'remain_yds_div_def_box', 'def_dl_count', 'td_prob', 'wr_to_db_ratio', 'game_wind_div_game_temp', 'ep_half_sec_ratio', 'week', 'prev1_wpa', 'prev4_wpa', 'prev2_wpa', 'off_hb_count', 'defteam_score', 'half_seconds_remaining', 'ep', 'game_wind', 'prev1_yards_gained', 'remain_yds_div_score_diff', 'remain_yds_div_off_hb_count', 'half_seconds_prod_score_diff', 'defenders_in_box', 'posteam_timeouts_remaining', 'play_sequence_series', 'def_lb_count', 'def_db_count', 'prev4_yards_gained', 'fg_prob', 'half_seconds_div_score_diff', 'remain_yds_prod_def_box']\n",
      " \n",
      "categorical features: 16 : ['posteam', 'posteam_type', 'defteam', 'roof', 'surface', 'offense_formation', 'offense_personnel', 'defense_personnel', 'game_weather', 'play_type_prev1', 'play_type_prev2', 'play_type_prev3', 'play_type_prev4', 'drive_start', 'posteam_season', 'defteam_season']\n",
      " \n",
      "feature count: 155\n"
     ]
    }
   ],
   "source": [
    "# Create feature type lists for column transform stage of the pipeline\n",
    "ordinal_features = X_train.columns[X_train.isin([1,2,3,4,5]).all()].tolist()\n",
    "categorical_features = list(X_train.select_dtypes(include='object'))\n",
    "boolean_features = X_train.columns[X_train.isin([0, 1]).all()].tolist()\n",
    "\n",
    "# define numeric features as remaining features not in ordinal categorical or boolean lists\n",
    "numeric_features = list(set(X_train.columns) - set(ordinal_features) - set(categorical_features) - set(boolean_features))\n",
    "\n",
    "#print('categorical features:', len(categorical_features), ':', categorical_features)\n",
    "print('ordinal features:', len(ordinal_features), ':', ordinal_features)\n",
    "print(' ')\n",
    "print('boolean features:', len(boolean_features), ':', boolean_features)\n",
    "print(' ')\n",
    "print('numeric features:', len(numeric_features), ':', numeric_features)\n",
    "print(' ')\n",
    "print('categorical features:', len(categorical_features), ':', categorical_features)\n",
    "print(' ')\n",
    "print('feature count:', len(initial_features))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:06:39.176034Z",
     "start_time": "2023-12-25T06:06:37.532504Z"
    }
   },
   "id": "e95804b4c341fcbb"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Custom transformer for IQR outlier exclusion\n",
    "class IQRTransformer:\n",
    "    def __init__(self, numerical_cols):\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            # Calculate the IQR for each numerical column\n",
    "            q1 = X[self.numerical_cols].quantile(0.25)\n",
    "            q3 = X[self.numerical_cols].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "\n",
    "            # Define the lower and upper bounds for outliers\n",
    "            self.lower_bound = (q1 - 1.5 * iqr).to_dict()\n",
    "            self.upper_bound = (q3 + 1.5 * iqr).to_dict()\n",
    "        else:\n",
    "            # Calculate the IQR for each numerical column\n",
    "            q1 = np.quantile(X[:, :], 0.25, axis=0)\n",
    "            q3 = np.quantile(X[:, :], 0.75, axis=0)\n",
    "            iqr = q3 - q1\n",
    "\n",
    "            # Define the lower and upper bounds for outliers\n",
    "            self.lower_bound = (q1 - 1.5 * iqr).tolist()\n",
    "            self.upper_bound = (q3 + 1.5 * iqr).tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            # Exclude outliers based on the IQR for each numerical column\n",
    "            x_outlier_removed = X.copy()\n",
    "            for col in self.numerical_cols:\n",
    "                if col in self.lower_bound and col in self.upper_bound:\n",
    "                    x_outlier_removed = x_outlier_removed[\n",
    "                        (x_outlier_removed[col] >= self.lower_bound[col]) & (x_outlier_removed[col] <= self.upper_bound[col])\n",
    "                    ].dropna()\n",
    "        else:\n",
    "            # Exclude outliers based on the IQR for each numerical column\n",
    "            x_outlier_removed = X.copy()\n",
    "            for i, col in enumerate(self.numerical_cols):\n",
    "                if col in self.lower_bound and col in self.upper_bound:\n",
    "                    lower_bound = self.lower_bound[col]\n",
    "                    upper_bound = self.upper_bound[col]\n",
    "                    x_outlier_removed = x_outlier_removed[\n",
    "                        (x_outlier_removed[:, i] >= lower_bound) & (x_outlier_removed[:, i] <= upper_bound)\n",
    "                    ].dropna()\n",
    "\n",
    "        return x_outlier_removed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:07:16.763409Z",
     "start_time": "2023-12-25T06:07:16.752955Z"
    }
   },
   "id": "716f61f917c8a815"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best performance for RandomForest: 0.354247353552716\n",
      "Best parameters: {'clf__bootstrap': True, 'clf__ccp_alpha': 0.0005361140014825931, 'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 0.23614145682895635, 'clf__max_samples': 0.05776517684749231, 'clf__min_impurity_decrease': 1.995214754838472e-09, 'clf__min_samples_leaf': 0.020787879125554312, 'clf__min_samples_split': 0.010976120471026344, 'clf__min_weight_fraction_leaf': 0.1559199188506055, 'clf__n_jobs': 6, 'clf__oob_score': False, 'clf__random_state': 67, 'clf__warm_start': True, 'select__k': 56, 'smpl__n_neighbors': 7, 'clf__n_estimators': 1000}\n",
      "\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best performance for ExtraTrees: 0.3708411941095795\n",
      "Best parameters: {'clf__n_estimators': 500}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the transformations per data type\n",
    "num_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "                            ('iqr_outlier', IQRTransformer(numerical_cols=numeric_features)),\n",
    "                            ('scaler', feature_scaler),\n",
    "                           ])\n",
    "\n",
    "cat_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                            ('cat_encoder', LeaveOneOutEncoder(handle_missing='value', handle_unknown='value', sigma=sigma, random_state=67)),\n",
    "                            ])\n",
    "\n",
    "ord_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                            ('ordinal_encoder', LeaveOneOutEncoder(handle_missing='value', handle_unknown='value', sigma=sigma, random_state=67)),\n",
    "                           ])\n",
    "\n",
    "preprocessing = ColumnTransformer(transformers=[('numeric_transform', num_trans, numeric_features),\n",
    "                                                ('categorical_transform', cat_trans, categorical_features),\n",
    "                                                ('ordinal_transform', ord_trans, ordinal_features),\n",
    "                                                ],\n",
    "                                     remainder='passthrough',\n",
    "                                    )\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    ('RandomForest', RandomForestClassifier()),\n",
    "    ('ExtraTrees', ExtraTreesClassifier()),\n",
    "    #('GradientBoosting', GradientBoostingClassifier()),\n",
    "    #('AdaBoost', AdaBoostClassifier()),\n",
    "    #('XGBoost', XGBClassifier()),\n",
    "]\n",
    "\n",
    "# Create and run the pipeline\n",
    "for model_name, model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('select', SelectKBest()),\n",
    "        ('smpl', ADASYN(sampling_strategy='not majority', random_state=67)),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    if model_name == 'RandomForest':\n",
    "        params = {\n",
    "            'select__k': randint(20, 60),\n",
    "            'smpl__n_neighbors': randint(4, 8),                             # Only for sampling_strategy='not majority'\n",
    "            'clf__bootstrap': [True],\n",
    "            'clf__ccp_alpha': loguniform(1e-06, 1e-01),                     # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "            'clf__criterion': ['gini','entropy'],\n",
    "            'clf__max_depth': randint(5, 30),\n",
    "            'clf__max_features': loguniform(0.10, 0.35), \n",
    "            'clf__min_impurity_decrease': loguniform(1e-09, 1e-04),\n",
    "            'clf__max_samples': loguniform(0.02, 0.49),                     # Only for bootstrap=True\n",
    "            'clf__min_samples_leaf': loguniform(0.005, 0.20),\n",
    "            'clf__min_samples_split': loguniform(0.005, 0.20),\n",
    "            'clf__min_weight_fraction_leaf': loguniform(0.005, 0.20),\n",
    "            'clf__oob_score': [True, False],                                # Only for bootstrap=True\n",
    "            'clf__warm_start': [True, False],\n",
    "            'clf__n_jobs': [6],\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "    \n",
    "    elif model_name == 'Extra Trees':\n",
    "        params = {\n",
    "            'select__k': randint(20, 60),\n",
    "            'smpl__n_neighbors': randint(4, 8),                       # Only for sampling_strategy='not majority\n",
    "            'clf__bootstrap': [True, False],\n",
    "            'clf__ccp_alpha': loguniform(1e-06, 1e-01),               # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "            'clf__criterion': ['gini','entropy'],\n",
    "            'clf__max_depth': randint(5, 80),\n",
    "            'clf__max_features': loguniform(0.50, 0.95),\n",
    "            'clf__max_leaf_nodes': randint(20, 70),\n",
    "            #'clf__max_samples': loguniform(0.10, 0.50),               # Only for bootstrap=True\n",
    "            'clf__min_impurity_decrease': loguniform(1e-05, 1e-01),\n",
    "            'clf__min_samples_leaf': loguniform(0.05, 0.30),\n",
    "            'clf__min_samples_split': loguniform(0.005, 0.15),\n",
    "            'clf__min_weight_fraction_leaf': loguniform(0.05, 0.25),\n",
    "            'clf__oob_score': [False],                                # Only for bootstrap=True\n",
    "            'clf__warm_start': [True, False],\n",
    "            'clf__n_jobs': [6],\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "    \n",
    "    elif model_name == 'GradientBoosting':\n",
    "        params = {\n",
    "            'select__k': randint(20, 60),\n",
    "            'smpl__n_neighbors': randint(4, 8),                       # Only for sampling_strategy='not majority\n",
    "            'clf__criterion': ['friedman_mse'],\n",
    "            'clf__ccp_alpha': loguniform(1e-06, 1e-01),  # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "            'clf__learning_rate': loguniform(1e-05, 1e-00),\n",
    "            #'clf__loss': ['log_loss'],                                 # Not available for multiclass    \n",
    "            'clf__max_depth': randint(25, 60),\n",
    "            'clf__max_features': loguniform(0.45, 0.85), \n",
    "            'clf__max_leaf_nodes': randint(20, 50),\n",
    "            'clf__min_weight_fraction_leaf': loguniform(0.30, 0.50),   # Must be <= 0.5\n",
    "            'clf__min_impurity_decrease': loguniform(1e-08, 1e-04),\n",
    "            'clf__min_samples_leaf': loguniform(0.01, 0.25),\n",
    "            'clf__min_samples_split': loguniform(0.10, 0.35),\n",
    "            'clf__n_iter_no_change': [200],\n",
    "            'clf__tol': loguniform(1e-08, 1e-03),\n",
    "            'clf__validation_fraction': loguniform(0.05, 0.15),\n",
    "            'clf__warm_start': [True, False],\n",
    "            'clf__subsample': loguniform(0.65, 1.0),\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "        \n",
    "    elif model_name == 'AdaBoost':\n",
    "        params = {\n",
    "            'select__k': randint(20, 60),\n",
    "            'smpl__n_neighbors': randint(4, 8),                       # Only for sampling_strategy='not majority\n",
    "            'clf__algorithm': ['SAMME','SAMME.R'],\n",
    "            'clf__learning_rate': loguniform(1e-08, 1e-01),\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "    \n",
    "    elif model_name == 'XGBoost':\n",
    "        params = {\n",
    "            'select__k': randint(20, 60),\n",
    "            'smpl__n_neighbors': randint(4, 8),                       # Only for sampling_strategy='not majority\n",
    "            'clf__booster': ['gbtree','dart'],\n",
    "            'clf__max_depth': [6],\n",
    "            'clf__grow_policy': ['depthwise','lossguide'],\n",
    "            'clf__objective': ['multi:softprob'],\n",
    "            'clf__eval_metric': ['auc'],\n",
    "            'clf__seed': [67],\n",
    "        }\n",
    "\n",
    "    search = HalvingRandomSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=params,\n",
    "        scoring=scoring,\n",
    "        factor=halving_parameter,\n",
    "        resource='clf__n_estimators',\n",
    "        n_candidates='exhaust',\n",
    "        min_resources=min_resource,\n",
    "        max_resources=max_resource,\n",
    "        aggressive_elimination=False,\n",
    "        return_train_score=True,\n",
    "        refit=True,\n",
    "        cv=n_cross_validation,\n",
    "        n_jobs=6,\n",
    "        error_score='raise',\n",
    "        random_state=67,\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best performance for {model_name}: {search.best_score_}\")\n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-25T06:10:03.242919Z",
     "start_time": "2023-12-25T06:07:17.982018Z"
    }
   },
   "id": "58cc5161"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HalvingRandomSearchCV runtime: 0.16 hours\n"
     ]
    }
   ],
   "source": [
    "# Calculate workbook processing time in hours\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print('Total HalvingRandomSearchCV runtime:', round(total_time / 3600, 2), 'hours')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T06:10:03.255022Z",
     "start_time": "2023-12-25T06:10:03.248728Z"
    }
   },
   "id": "d7e4b6574bc08686"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-25T06:00:32.135667Z"
    }
   },
   "id": "8b4ac4275dcfbe6"
  }
 ],
 "metadata": {
  "colab": {
   "name": "nfl_offensive_play_classification_v1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
