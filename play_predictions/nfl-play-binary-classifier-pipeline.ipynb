{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore',category=ImportWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import category_encoders as ce\n",
    "from scipy.stats import randint\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from BorutaShap import BorutaShap\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler # StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingRandomSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import operator\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "774348c602e5ca1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train test split parameters\n",
    "test_holdout_percentage = 0.20\n",
    "\n",
    "# Leave One Out Encoder Sigma value\n",
    "sigma = 0.05\n",
    "\n",
    "# Feature model parameters\n",
    "feature_model_n_estimators = 200\n",
    "feature_model_max_depth = 70\n",
    "feature_model_max_features = 0.50\n",
    "\n",
    "# BorutaShap parameters\n",
    "feature_model_n_trials = 200\n",
    "\n",
    "# ADASYN sampling multiplier\n",
    "adasyn_class_multiplier = 2\n",
    "\n",
    "# Specify model pipeline parameters\n",
    "scoring = 'accuracy'\n",
    "n_cross_validation = 5\n",
    "\n",
    "# Specify the HalvingRandomSearchCV parameters\n",
    "halving_parameter = 2.0\n",
    "max_resource = 2000\n",
    "resource_divisor = 2.0\n",
    "min_resource = int(round((max_resource / resource_divisor), 0))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39c59abc33e5e515"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create timer to calculate total workbook time in hours\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc8446203dc414e"
  },
  {
   "cell_type": "markdown",
   "id": "c4f8e047",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IMPORT PROCESSED NFL-DATA-PY CSV FILE\n",
    "##### https://pypi.org/project/nfl-data-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import csv file from nfl-data-py\n",
    "df = pd.read_csv(r'/Users/ttas2/Documents/Python/nfl-machine-learning-models/output_files/nfl_post_processing_run_pass_classification_data.csv')\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8d686327dce3e32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print columns with missing values\n",
    "print(df.columns[df.isnull().any()].tolist())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "629bc39586b0fba6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert binary columns to integers\n",
    "binary_columns = df.columns[df.isin([0,1]).all()].tolist()\n",
    "df[binary_columns] = df[binary_columns].apply(pd.to_numeric, downcast='integer', errors='coerce', axis=1)\n",
    "\n",
    "df.sample(2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41f7422bcc2cf003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9bcb28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Target frequency\n",
    "target_count = df.play_type.value_counts(normalize=True)\n",
    "target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['play_type'] = np.where(df['play_type'] == 'pass', 1, 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91112ef9f7a1ba3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAIN TEST SPLIT\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c140526b778c182"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943bbf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data into target and feature datasets\n",
    "X, y = df.loc[:, df.columns != 'play_type'], df['play_type']\n",
    "\n",
    "initial_features = X.columns.to_list()\n",
    "\n",
    "# Create train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_holdout_percentage, random_state=67)\n",
    "\n",
    "print(X_train.shape[1], 'initial features before processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd4c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BASELINE MODEL\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9513e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create and fit baseline model to compare performance\n",
    "baseline_model = DummyClassifier(strategy='most_frequent', random_state=67)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate model accuracy on test data\n",
    "y_baseline_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print(f\"Baseline accuracy: {round(accuracy_score(y_test,y_baseline_pred)*100, 1)}%\")\n",
    "print(f\"Baseline f1 score: {round(f1_score(y_test,y_baseline_pred)*100, 1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ENCODE CATEGORICAL FEATURES\n",
    "##### https://contrib.scikit-learn.org/category_encoders/leaveoneout.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0f3ad4dbdd2f444"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encoded column represents mean response over all rows for this category, providing one-column representation while avoiding direct response leakage\n",
    "\n",
    "pre_features = X_train.columns.to_list()\n",
    "categorical_features = list(X_train.select_dtypes(include='object'))\n",
    "\n",
    "# Sigma adds normal (Gaussian) distribution noise into training data in order to decrease over-fitting (testing data are untouched). Sigma gives the standard deviation (spread or “width”) of the normal distribution. The optimal value is commonly between 0.05 and 0.6. The default is to not add noise, but that leads to significantly suboptimal results.\n",
    "encoder = ce.LeaveOneOutEncoder(return_df=True, cols=categorical_features, handle_missing='value', handle_unknown='value', sigma=sigma, random_state=67, drop_invariant=False)\n",
    "\n",
    "X_train = encoder.fit_transform(X_train, y_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "post_features = X_train.columns.to_list()\n",
    "\n",
    "# Compare 2 lists and identify elements in first list not in second list\n",
    "def diff(list1, list2):\n",
    "    return list(set(list1) - set(list2))\n",
    "\n",
    "print('Total observations in training dataset:', len(X_train))\n",
    "print('Total features before encoding:', len(pre_features))\n",
    "print(' ')\n",
    "print('Categorical features dropped due to invariance:', diff(pre_features, post_features))\n",
    "print(' ')\n",
    "print('Total features after categorical encoding:', len(post_features))\n",
    "print('Column names:', X_train.columns.to_list())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d33d4e0b73750e26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FEATURE SELECTION\n",
    "##### https://pypi.org/project/BorutaShap/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65fe86e88f378c61"
  },
  {
   "cell_type": "raw",
   "source": [
    "feature_model =  XGBClassifier()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93c2b0bed128bd09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_model = RandomForestClassifier(ccp_alpha=1e-03,                             # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "                                      criterion='gini',\n",
    "                                      max_depth=feature_model_max_depth, \n",
    "                                      max_features=feature_model_max_features,\n",
    "                                      max_leaf_nodes=50,                           # max_leaf_nodes is not supported for bootstrap=False\n",
    "                                      max_samples=0.30,                            # max_samples is not supported for bootstrap=False\n",
    "                                      min_impurity_decrease=1e-05,                 # A node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "                                      #min_samples_leaf=0.02,\n",
    "                                      #min_samples_split=0.02,\n",
    "                                      #min_weight_fraction_leaf=0.03,\n",
    "                                      n_estimators=feature_model_n_estimators,\n",
    "                                      class_weight='balanced_subsample',\n",
    "                                      bootstrap=True,\n",
    "                                      oob_score=False,                              # Only for bootstrap=True\n",
    "                                      warm_start=False,\n",
    "                                      n_jobs=6,\n",
    "                                      random_state=67,\n",
    "                                       )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39e692ffcbfd70ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# no model selected default is Random Forest\n",
    "Feature_Selector = BorutaShap(importance_measure='shap',\n",
    "                              classification=True,\n",
    "                              model=feature_model,\n",
    "                              )\n",
    "\n",
    "Feature_Selector.fit(X=X_train,\n",
    "                    y=y_train,\n",
    "                    n_trials=feature_model_n_trials,\n",
    "                    sample=False,\n",
    "                    random_state=67,\n",
    "                    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7034bfcd562178"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot selected features with shap values on x-axis\n",
    "Feature_Selector.plot(which_features='accepted', figsize=(18, 10), y_scale='log')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c20134f76d62fa54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drops features that were identified by BorutaShap as not important\n",
    "features_to_remove = Feature_Selector.features_to_remove\n",
    "\n",
    "X_train = X_train.drop(columns=features_to_remove)\n",
    "X_test = X_test.drop(columns=features_to_remove)\n",
    "\n",
    "print('Training features:', X_train.shape[1])\n",
    "print('Testing features:', X_test.shape[1])\n",
    "print('Most important features:', X_train.columns.to_list())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afa5c66c26a42f87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate workbook processing time in hours\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print('Total time:', round(total_time / 3600, 2), 'hours')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "303ed2263cd313f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL PIPELINE\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html\n",
    "##### https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html\n",
    "##### https://imbalanced-learn.org/stable/references/over_sampling.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
    "##### https://xgboost.readthedocs.io/en/stable/parameter.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28eb7c49ea06b6d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create feature type lists for column transform stage of the pipeline\n",
    "ordinal_features = X_train.columns[X_train.isin([1,2,3,4,5]).all()].tolist()\n",
    "categorical_features = list(X_train.select_dtypes(include='object'))\n",
    "boolean_features = X_train.columns[X_train.isin([0, 1]).all()].tolist()\n",
    "\n",
    "numeric_features = [x for x in X_train.columns if x not in ordinal_features]\n",
    "numeric_features = [x for x in numeric_features if x not in categorical_features]\n",
    "numeric_features = [x for x in numeric_features if x not in boolean_features]\n",
    "\n",
    "#print('categorical features:', len(categorical_features), ':', categorical_features)\n",
    "print('ordinal features:', len(ordinal_features), ':', ordinal_features)\n",
    "print('boolean features:', len(boolean_features), ':', boolean_features)\n",
    "print('numeric features:', len(numeric_features), ':', numeric_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e95804b4c341fcbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Outlier removal\n",
    "def iqr_outliers(x, features):\n",
    "\n",
    "    out_index_list = []\n",
    "        \n",
    "    for col in features:\n",
    "        q1 = np.nanpercentile(x[col], 25.)\n",
    "        q3 = np.nanpercentile(x[col], 75.)\n",
    "        \n",
    "        cut_off = (q3 - q1) * 1.5\n",
    "        upper, lower = q3 + cut_off, q1 - cut_off\n",
    "                \n",
    "        outliers_index = x[col][(x[col] < lower) | (x[col] > upper)].index.tolist()\n",
    "        out_index_list.extend(outliers_index)\n",
    "        \n",
    "    # Remove duplicates\n",
    "    list(set(out_index_list)).sort()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "3e4ff9bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify the transformations per data type\n",
    "num_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "                            ('iqr_outlier', iqr_outliers(X_train, numeric_features)),\n",
    "                            ('scaler', MinMaxScaler()),\n",
    "                           ])\n",
    "\n",
    "cat_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                            ('onehot_encoder', OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist')),\n",
    "                            ])\n",
    "\n",
    "ord_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                            ('ordinal_encoder', OrdinalEncoder(categories='auto', handle_unknown='error')),\n",
    "                            ('scaler', MinMaxScaler()),\n",
    "                           ])\n",
    "                             \n",
    "Column_Transform = ColumnTransformer(transformers=[('numeric_transform', num_trans, numeric_features),\n",
    "                                                   ('categorical_transform', cat_trans, categorical_features),\n",
    "                                                   ('ordinal_transform', ord_trans, ordinal_features),\n",
    "                                                   ],\n",
    "                                     remainder='passthrough',\n",
    "                                    )"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "58cc5161"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17593a5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Specify number of target classes\n",
    "n_classes = y_train.nunique() * adasyn_class_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3074a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_search():\n",
    "    \n",
    "    pipeline1 = Pipeline([\n",
    "    ('col', Column_Transform),\n",
    "    ('smpl', ADASYN(n_neighbors=n_classes, sampling_strategy='not majority', random_state=67)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "    ])\n",
    "    \n",
    "    pipeline2 = Pipeline([\n",
    "    ('col', Column_Transform),\n",
    "    ('smpl', ADASYN(n_neighbors=n_classes, sampling_strategy='not majority', random_state=67)),\n",
    "    ('clf', ExtraTreesClassifier()),\n",
    "    ])\n",
    "    \n",
    "    pipeline3 = Pipeline([\n",
    "    ('col', Column_Transform),\n",
    "    ('smpl', ADASYN(n_neighbors=n_classes, sampling_strategy='not majority', random_state=67)),\n",
    "    ('clf', GradientBoostingClassifier()),\n",
    "    ])\n",
    "    \n",
    "    pipeline4 = Pipeline([\n",
    "    ('col', Column_Transform),\n",
    "    ('smpl', ADASYN(n_neighbors=n_classes, sampling_strategy='not majority', random_state=67)),\n",
    "    ('clf', AdaBoostClassifier()),\n",
    "    ])\n",
    "    \n",
    "    # RandomForestClassifier\n",
    "    parameters1 = {\n",
    "    'clf__bootstrap': [True, False],\n",
    "    'clf__ccp_alpha': loguniform(1e-07, 1e-01),              # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "    'clf__criterion': ['gini'],\n",
    "    'clf__max_depth': randint(20, 80),\n",
    "    'clf__max_features': loguniform(0.02, 0.50), \n",
    "    'clf__min_impurity_decrease': loguniform(1e-07, 1e-03),\n",
    "    #'clf__max_samples': loguniform(0.02, 0.49),              # max_samples is not supported for bootstrap=False\n",
    "    'clf__min_samples_leaf': loguniform(0.02, 0.40),\n",
    "    'clf__min_samples_split': loguniform(0.02, 0.40),\n",
    "    'clf__min_weight_fraction_leaf': loguniform(0.02, 0.40),\n",
    "    'clf__oob_score': [False],                                # Only for bootstrap=True\n",
    "    'clf__warm_start': [True, False],\n",
    "    'clf__n_jobs': [6],\n",
    "    'clf__random_state': [67],\n",
    "    }\n",
    "\n",
    "    # ExtraTreesClassifier\n",
    "    parameters2 = {\n",
    "    'clf__bootstrap': [True, False],\n",
    "    'clf__ccp_alpha': loguniform(1e-06, 1e-02),               # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "    'clf__criterion': ['gini'],\n",
    "    'clf__max_depth': randint(30, 80),\n",
    "    'clf__max_features': loguniform(0.25, 0.95),\n",
    "    'clf__max_leaf_nodes': randint(25, 75),\n",
    "    #'clf__max_samples': loguniform(0.10, 0.50),               # max_samples is not supported for bootstrap=False\n",
    "    'clf__min_impurity_decrease': loguniform(1e-06, 1e-02),\n",
    "    'clf__min_samples_leaf': loguniform(0.02, 0.30),\n",
    "    'clf__min_samples_split': loguniform(0.02, 0.30),\n",
    "    'clf__min_weight_fraction_leaf': loguniform(0.02, 0.30),\n",
    "    'clf__oob_score': [False],                                # Only for bootstrap=True\n",
    "    'clf__warm_start': [True, False],\n",
    "    'clf__n_jobs': [6],\n",
    "    'clf__random_state': [67],\n",
    "    }\n",
    "    \n",
    "    # GradientBoostingClassifier\n",
    "    parameters3 = {\n",
    "    'clf__criterion': ['friedman_mse'],\n",
    "    'clf__ccp_alpha': loguniform(1e-06, 1e-02),                # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "    'clf__learning_rate': loguniform(1e-05, 1e-01),\n",
    "    'clf__loss': ['log_loss'],\n",
    "    'clf__max_depth': randint(15, 80),\n",
    "    'clf__max_features': loguniform(0.20, 0.75), \n",
    "    'clf__max_leaf_nodes': randint(10, 70),\n",
    "    'clf__min_weight_fraction_leaf': loguniform(0.10, 0.50),   # New in version 0.24.\n",
    "    'clf__min_impurity_decrease': loguniform(1e-07, 1e-01),\n",
    "    'clf__min_samples_leaf': loguniform(0.05, 0.55),\n",
    "    'clf__min_samples_split': loguniform(0.05, 0.55),\n",
    "    'clf__n_iter_no_change': [150],\n",
    "    'clf__tol': loguniform(1e-06, 1e-02),\n",
    "    'clf__validation_fraction': loguniform(0.10, 0.15),\n",
    "    'clf__warm_start': [True, False],\n",
    "    'clf__subsample': loguniform(0.90, 1.00),                  # Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias\n",
    "    'clf__random_state': [67],\n",
    "    }\n",
    "\n",
    "    # AdaBoostClassifier\n",
    "    parameters4  = {\n",
    "    'clf__algorithm': ['SAMME','SAMME.R'],\n",
    "    'clf__learning_rate':  loguniform(1e-10, 1e-01),\n",
    "    'clf__random_state': [67],\n",
    "    }\n",
    "\n",
    "    pars = [parameters1, parameters2, parameters3, parameters4]\n",
    "    pips = [pipeline1, pipeline2, pipeline3, pipeline4]\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(pars)):\n",
    "        \n",
    "        rs = HalvingRandomSearchCV(pips[i],\n",
    "                                   pars[i],\n",
    "                                   factor=halving_parameter,\n",
    "                                   resource='clf__n_estimators',\n",
    "                                   n_candidates='exhaust',\n",
    "                                   min_resources=min_resource,\n",
    "                                   max_resources=max_resource,\n",
    "                                   scoring=scoring,\n",
    "                                   aggressive_elimination=False,\n",
    "                                   return_train_score=True,\n",
    "                                   refit=True,                   \n",
    "                                   cv=n_cross_validation,\n",
    "                                   n_jobs=6,\n",
    "                                   verbose=1,\n",
    "                                   random_state=67,\n",
    "                                   error_score='raise',\n",
    "                                  )\n",
    "\n",
    "        # Fit models on training data\n",
    "        rs = rs.fit(X_train, y_train)\n",
    "        \n",
    "        # Apply models to test data to determine model performance\n",
    "        y_pred = rs.predict(X_test)\n",
    "        y_pred_prob = rs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        print(\" \")\n",
    "        print(\" \")\n",
    "        \n",
    "        # storing model results\n",
    "        result.append({\n",
    "        'grid': rs,\n",
    "        'cv results': rs.cv_results_,\n",
    "        'train accuracy score': rs.best_score_,\n",
    "        'best params': rs.best_params_, \n",
    "        'best estimator': rs.best_estimator_,\n",
    "        'feature importance': rs.best_estimator_.named_steps['clf'].feature_importances_,\n",
    "        'test f1 score': f1_score(y_test, y_pred, average='micro'),\n",
    "        'test accuracy score': accuracy_score(y_test, y_pred),\n",
    "        'test balanced accuracy score': balanced_accuracy_score(y_test, y_pred),\n",
    "        'test roc auc score': roc_auc_score(y_test, y_pred_prob),\n",
    "        'test classification report': classification_report(y_test, y_pred, target_names=['pass','run'], digits=5),\n",
    "        'test confusion matrix': confusion_matrix(y_test, y_pred),\n",
    "        'cv': rs.cv,\n",
    "        'model #': i + 1\n",
    "        })\n",
    "\n",
    "    # sorting results by best test score\n",
    "    result = sorted(result, key=operator.itemgetter('test f1 score'), reverse=True)\n",
    "    \n",
    "    print(' ')\n",
    "    for element in result:\n",
    "        if element['model #']==1:\n",
    "            print('Random Forest classifier: ')\n",
    "        elif element['model #']==2:\n",
    "            print('ExtraTrees classifier: ')\n",
    "        elif element['model #']==3:\n",
    "            print('GradientBoosting classifier: ')\n",
    "        elif element['model #']==4:\n",
    "            print('AdaBoost classifier: ')\n",
    "        else:\n",
    "            print('Other: ')  \n",
    "        \n",
    "        print('Parameters:  ' + str(element['best params']))\n",
    "        print(' ')\n",
    "        print('Train accuracy score:         ' + str(element['train accuracy score']))\n",
    "        print('Test accuracy score:          ' + str(element['test accuracy score']))\n",
    "        print('Test balanced accuracy score: ' + str(element['test accuracy score']))\n",
    "        print('Test f1 score:                ' + str(element['test f1 score']))\n",
    "        print('Test roc auc score:           ' + str(element['test roc auc score']))\n",
    "        print(' ')\n",
    "        print(element['test classification report'])\n",
    "        print(element['test confusion matrix'])\n",
    "        print(' ')\n",
    "        print('-----------------------')\n",
    "        print(' ')\n",
    "        \n",
    "        # Export best model as csv file\n",
    "        pd.DataFrame(element['cv results']).to_csv(r'/Users/ttas2/Documents/Python/nfl-machine-learning-models/output_files/run_pass_classifier_model.csv')\n",
    "        pd.DataFrame(element['feature importance'], index=X_train.columns).to_csv(r'/Users/ttas2/Documents/Python/nfl-machine-learning-models/output_files/run_pass_classifier_feature_importance.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2a726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "random_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate workbook processing time in hours\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print('Total process time:', round(total_time / 3600, 2), 'hours')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e4b6574bc08686"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LIST RESULTS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb1540d2bf6bbb08"
  },
  {
   "cell_type": "raw",
   "source": [
    "ExtraTrees classifier: \n",
    "\n",
    "Parameters:  {'clf__bootstrap': True, 'clf__ccp_alpha': 0.00015254771955752704, 'clf__criterion': 'gini', 'clf__max_depth': 40, 'clf__max_features': 0.7109690887594401, 'clf__max_leaf_nodes': 50, 'clf__max_samples': 0.27100895887372795, 'clf__min_impurity_decrease': 1.737767690156849e-06, 'clf__min_samples_leaf': 0.04867520359234982, 'clf__min_samples_split': 0.03267231099814945, 'clf__min_weight_fraction_leaf': 0.17121296400160577, 'clf__n_jobs': 6, 'clf__oob_score': True, 'clf__random_state': 67, 'clf__warm_start': False, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.7328509971240786\n",
    "Test accuracy score:          0.7374504344891588\n",
    "Sigma: 0.05\n",
    "\n",
    "Parameters:  {'clf__bootstrap': True, 'clf__ccp_alpha': 0.00015254771955752704, 'clf__criterion': 'gini', 'clf__max_depth': 40, 'clf__max_features': 0.7109690887594401, 'clf__max_leaf_nodes': 50, 'clf__max_samples': 0.27100895887372795, 'clf__min_impurity_decrease': 1.737767690156849e-06, 'clf__min_samples_leaf': 0.04867520359234982, 'clf__min_samples_split': 0.03267231099814945, 'clf__min_weight_fraction_leaf': 0.17121296400160577, 'clf__n_jobs': 6, 'clf__oob_score': True, 'clf__random_state': 67, 'clf__warm_start': False, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.7234644379512698\n",
    "Test accuracy score:          0.729688686408504\n",
    "Sigma: 0.30\n",
    "\n",
    "\n",
    "Sigma: 0.45\n",
    "\n",
    "#########################################################################################################################\n",
    " \n",
    "GradientBoosting classifier: \n",
    "\n",
    "Parameters:  {'clf__ccp_alpha': 0.00015254771955752704, 'clf__criterion': 'friedman_mse', 'clf__learning_rate': 0.027253760954919798, 'clf__loss': 'log_loss', 'clf__max_depth': 22, 'clf__max_features': 0.40793199792771945, 'clf__max_leaf_nodes': 37, 'clf__min_impurity_decrease': 2.290802125320806e-07, 'clf__min_samples_leaf': 0.12625159106580724, 'clf__min_samples_split': 0.08335712129212816, 'clf__min_weight_fraction_leaf': 0.4485327689331512, 'clf__n_iter_no_change': 100, 'clf__random_state': 67, 'clf__subsample': 0.9712183089566733, 'clf__tol': 1.54021456749761e-06, 'clf__validation_fraction': 0.13951652852936217, 'clf__warm_start': False, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.6996287115689432\n",
    "Test accuracy score:          0.7120560195731038\n",
    "Sigma: 0.05\n",
    "\n",
    "Parameters:  {'clf__ccp_alpha': 0.00015254771955752704, 'clf__criterion': 'friedman_mse', 'clf__learning_rate': 0.027253760954919798, 'clf__loss': 'log_loss', 'clf__max_depth': 22, 'clf__max_features': 0.40793199792771945, 'clf__max_leaf_nodes': 37, 'clf__min_impurity_decrease': 2.290802125320806e-07, 'clf__min_samples_leaf': 0.12625159106580724, 'clf__min_samples_split': 0.08335712129212816, 'clf__min_weight_fraction_leaf': 0.4485327689331512, 'clf__n_iter_no_change': 100, 'clf__random_state': 67, 'clf__subsample': 0.9712183089566733, 'clf__tol': 1.54021456749761e-06, 'clf__validation_fraction': 0.13951652852936217, 'clf__warm_start': False, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.6936802901198661\n",
    "Test accuracy score:          0.710621783514722\n",
    "Sigma: 0.30\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "Random Forest classifier: \n",
    "\n",
    "Parameters:  {'clf__bootstrap': True, 'clf__ccp_alpha': 6.621555286692298e-05, 'clf__criterion': 'gini', 'clf__max_depth': 30, 'clf__max_features': 0.2629710119017867, 'clf__min_impurity_decrease': 0.0007295057635380967, 'clf__min_samples_leaf': 0.1383043350125251, 'clf__min_samples_split': 0.12341278988130677, 'clf__min_weight_fraction_leaf': 0.02814905818969609, 'clf__n_jobs': 6, 'clf__oob_score': True, 'clf__random_state': 67, 'clf__warm_start': False, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.7047965289697502\n",
    "Test accuracy score:          0.7073314772631402\n",
    "Sigma: 0.05\n",
    "Parameters:  {'clf__bootstrap': True, 'clf__ccp_alpha': 6.621555286692298e-05, 'clf__criterion': 'gini', 'clf__max_depth': 30, 'clf__max_features': 0.2629710119017867, 'clf__min_impurity_decrease': 0.0007295057635380967, 'clf__min_samples_leaf': 0.1383043350125251, 'clf__min_samples_split': 0.12341278988130677, 'clf__min_weight_fraction_leaf': 0.02814905818969609, 'clf__n_jobs': 6, 'clf__oob_score': True, 'clf__random_state': 67, 'clf__warm_start': False, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.6836397581183526\n",
    "Test accuracy score:          0.6921454484096853\n",
    "Sigma: 0.30\n",
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "AdaBoost classifier: \n",
    "\n",
    "AdaBoost classifier: \n",
    "Parameters:  {'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.00014894752087814164, 'clf__random_state': 67, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.7220932923696615\n",
    "Test accuracy score:          0.724373576309795\n",
    "Sigma: 0.05\n",
    "\n",
    "Parameters:  {'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.0005791835996776365, 'clf__random_state': 67, 'clf__n_estimators': 2000}\n",
    "Train accuracy score:         0.7171995585883075\n",
    "Test accuracy score:          0.7187209989032313\n",
    "Sigma 0.30\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31d91f3312f47115"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c4c9d9e5feec16b"
  }
 ],
 "metadata": {
  "colab": {
   "name": "nfl_offensive_play_classification_v1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
