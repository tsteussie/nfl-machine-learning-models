{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore',category=ImportWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import randint, loguniform\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingRandomSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report # plot_confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:12.184903Z",
     "start_time": "2023-12-24T15:46:08.691855Z"
    }
   },
   "id": "774348c602e5ca1e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Train test split parameters\n",
    "test_holdout_percentage = 0.10\n",
    "\n",
    "# Leave One Out Encoder Sigma value - 0.04 is the top performing value.\n",
    "sigma = 0.04                                                                 # Tested parameters: 0.04, 0.05, 0.10, 0.30, 0.60\n",
    "\n",
    "# Feature scaler\n",
    "feature_scaler = RobustScaler()                                              # Tested parameters: MinMaxScaler(), StandardScaler(), MaxAbsScaler(), RobustScaler()\n",
    "\n",
    "# HalvingRandomSearchCV parameters\n",
    "scoring = 'accuracy'\n",
    "n_cross_validation = 3\n",
    "\n",
    "# Specify the HalvingRandomSearchCV parameters\n",
    "halving_parameter = 2.0\n",
    "max_resource = 2000\n",
    "resource_divisor = 2.0\n",
    "min_resource = int(round((max_resource / resource_divisor), 0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:12.197553Z",
     "start_time": "2023-12-24T15:46:12.190924Z"
    }
   },
   "id": "39c59abc33e5e515"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create timer to calculate total workbook time in hours\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:12.200047Z",
     "start_time": "2023-12-24T15:46:12.196353Z"
    }
   },
   "id": "5dc8446203dc414e"
  },
  {
   "cell_type": "markdown",
   "id": "c4f8e047",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IMPORT PROCESSED NFL-DATA-PY CSV FILE\n",
    "##### https://pypi.org/project/nfl-data-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(60686, 156)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import csv file from nfl-data-py\n",
    "df = pd.read_csv(r'/Users/ttas2/Documents/Python/nfl-machine-learning-models/output_files/nfl_post_processing_run_pass_classification_data.csv')\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:13.352981Z",
     "start_time": "2023-12-24T15:46:12.202557Z"
    }
   },
   "id": "f8d686327dce3e32"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       week posteam posteam_type defteam  yardline_100   \n44481    18     NYG         away     PHI          31.0  \\\n10944    14     CHI         home     DET          49.0   \n\n       quarter_seconds_remaining  half_seconds_remaining   \n44481                         80                     980  \\\n10944                        781                    1681   \n\n       game_seconds_remaining  game_half  qtr  ...   \n44481                    2780          1    1  ...  \\\n10944                    3481          1    1  ...   \n\n       remain_yds_div_def_dl_count  remain_yds_prod_def_dl_count   \n44481                     0.833333                     13.333333  \\\n10944                     0.833333                     13.333333   \n\n       remain_yds_div_def_db_count remain_yds_prod_def_db_count   \n44481                     0.833333                    13.333333  \\\n10944                     0.666667                    16.666667   \n\n       remain_yds_div_score_diff  remain_yds_prod_score_diff   \n44481                   7.681159                    1.446541  \\\n10944                   6.309524                    1.761006   \n\n       run_ratio_off_priors  run_ratio_def_priors  posteam_season   \n44481              0.506250              0.678770        nyg_2022  \\\n10944              0.555829              0.579324        chi_2023   \n\n       defteam_season  \n44481        phi_2022  \n10944        det_2023  \n\n[2 rows x 156 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>posteam</th>\n      <th>posteam_type</th>\n      <th>defteam</th>\n      <th>yardline_100</th>\n      <th>quarter_seconds_remaining</th>\n      <th>half_seconds_remaining</th>\n      <th>game_seconds_remaining</th>\n      <th>game_half</th>\n      <th>qtr</th>\n      <th>...</th>\n      <th>remain_yds_div_def_dl_count</th>\n      <th>remain_yds_prod_def_dl_count</th>\n      <th>remain_yds_div_def_db_count</th>\n      <th>remain_yds_prod_def_db_count</th>\n      <th>remain_yds_div_score_diff</th>\n      <th>remain_yds_prod_score_diff</th>\n      <th>run_ratio_off_priors</th>\n      <th>run_ratio_def_priors</th>\n      <th>posteam_season</th>\n      <th>defteam_season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44481</th>\n      <td>18</td>\n      <td>NYG</td>\n      <td>away</td>\n      <td>PHI</td>\n      <td>31.0</td>\n      <td>80</td>\n      <td>980</td>\n      <td>2780</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.833333</td>\n      <td>13.333333</td>\n      <td>0.833333</td>\n      <td>13.333333</td>\n      <td>7.681159</td>\n      <td>1.446541</td>\n      <td>0.506250</td>\n      <td>0.678770</td>\n      <td>nyg_2022</td>\n      <td>phi_2022</td>\n    </tr>\n    <tr>\n      <th>10944</th>\n      <td>14</td>\n      <td>CHI</td>\n      <td>home</td>\n      <td>DET</td>\n      <td>49.0</td>\n      <td>781</td>\n      <td>1681</td>\n      <td>3481</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.833333</td>\n      <td>13.333333</td>\n      <td>0.666667</td>\n      <td>16.666667</td>\n      <td>6.309524</td>\n      <td>1.761006</td>\n      <td>0.555829</td>\n      <td>0.579324</td>\n      <td>chi_2023</td>\n      <td>det_2023</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 156 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert binary columns to integers\n",
    "binary_columns = df.columns[df.isin([0,1]).all()].tolist()\n",
    "df[binary_columns] = df[binary_columns].apply(pd.to_numeric, downcast='integer', errors='coerce', axis=1)\n",
    "\n",
    "df.sample(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:22.879621Z",
     "start_time": "2023-12-24T15:46:13.347696Z"
    }
   },
   "id": "41f7422bcc2cf003"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print columns with missing values\n",
    "print(df.columns[df.isnull().any()].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:23.147772Z",
     "start_time": "2023-12-24T15:46:23.071929Z"
    }
   },
   "id": "629bc39586b0fba6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9bcb28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:23.149089Z",
     "start_time": "2023-12-24T15:46:23.135240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "play_type\npass    0.598342\nrun     0.401658\nName: proportion, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target frequency\n",
    "target_count = df.play_type.value_counts(normalize=True)\n",
    "\n",
    "target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df['play_type'] = np.where(df['play_type'] == 'pass', 1, 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:23.169576Z",
     "start_time": "2023-12-24T15:46:23.145330Z"
    }
   },
   "id": "91112ef9f7a1ba3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAIN TEST SPLIT\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c140526b778c182"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4943bbf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:23.287937Z",
     "start_time": "2023-12-24T15:46:23.177108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier scale_pos_weight: 1.49\n"
     ]
    }
   ],
   "source": [
    "# split data into target and feature datasets\n",
    "X, y = df.loc[:, df.columns != 'play_type'], df['play_type']\n",
    "\n",
    "initial_features = X.columns.to_list()\n",
    "\n",
    "# Create train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_holdout_percentage, random_state=67)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cd4c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BASELINE MODEL\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e9513e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:23.331107Z",
     "start_time": "2023-12-24T15:46:23.273339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 60.1%\n",
      "Baseline f1 score: 75.0%\n"
     ]
    }
   ],
   "source": [
    "# Create and fit baseline model to compare performance\n",
    "baseline_model = DummyClassifier(strategy='most_frequent', random_state=67)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate model accuracy on test data\n",
    "y_baseline_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print(f\"Baseline accuracy: {round(accuracy_score(y_test,y_baseline_pred)*100, 1)}%\")\n",
    "print(f\"Baseline f1 score: {round(f1_score(y_test,y_baseline_pred)*100, 1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL PIPELINE\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html\n",
    "##### https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html\n",
    "##### https://imbalanced-learn.org/stable/references/over_sampling.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "##### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
    "##### https://xgboost.readthedocs.io/en/stable/parameter.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28eb7c49ea06b6d2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordinal features: 4 : ['game_half', 'qtr', 'down', 'remaining_downs']\n",
      " \n",
      "boolean features: 66 : ['goal_to_go', 'shotgun', 'no_huddle', 'div_game', 'report_eligible', 'dtg_99to90', 'dtg_89to60', 'dtg_59to45', 'dtg_44to35', 'dtg_34to21', 'dtg_20to10', 'dtg_09to00', 'prev1_big_play_pass', 'prev2_big_play_pass', 'prev3_big_play_pass', 'prev1_big_play_run', 'prev2_big_play_run', 'prev3_big_play_run', 'prev1_negative_pass', 'prev2_negative_pass', 'prev3_negative_pass', 'prev1_negative_run', 'prev2_negative_run', 'prev3_negative_run', 'prev1_play_off_penalty', 'prev1_play_def_penalty', 'prev2_play_off_penalty', 'prev2_play_def_penalty', 'prev3_play_off_penalty', 'prev3_play_def_penalty', 'prev1_play_run_outside', 'prev1_play_run_inside', 'prev1_play_pass_deep', 'prev1_play_pass_short', 'prev2_play_run_outside', 'prev2_play_run_inside', 'prev2_play_pass_deep', 'prev2_play_pass_short', 'prev3_play_run_outside', 'prev3_play_run_inside', 'prev3_play_pass_deep', 'prev3_play_pass_short', 'prev1_incomplete_pass', 'prev2_incomplete_pass', 'prev3_incomplete_pass', 'prev4_incomplete_pass', 'prev1_shotgun', 'prev2_shotgun', 'prev3_shotgun', 'prev1_qb_hit', 'prev2_qb_hit', 'prev3_qb_hit', 'prev1_no_huddle', 'prev2_no_huddle', 'prev3_no_huddle', 'prev1_first_down_pass', 'prev2_first_down_pass', 'prev3_first_down_pass', 'prev1_first_down_run', 'prev2_first_down_run', 'prev3_first_down_run', 'prev1_effct_play', 'prev2_effct_play', 'prev3_effct_play', 'two_min_warning', 'posteam_side']\n",
      " \n",
      "numeric features: 69 : ['game_wind_prod_game_temp', 'remain_yds_div_off_hb_count', 'off_ol_count', 'ydstogo', 'play_sequence_series', 'no_score_prob', 'ep', 'off_hb_count', 'total_line', 'def_lb_count', 'remain_yds_prod_score_diff', 'play_sequence_game', 'game_wind_div_game_temp', 'n_defense', 'wp', 'game_seconds_remaining', 'game_temp_div_game_humidity', 'half_seconds_div_score_diff', 'remain_yds_div_def_db_count', 'game_temp_prod_game_humidity', 'yardline_100', 'defteam_timeouts_remaining', 'defenders_in_box', 'defteam_score', 'score_differential', 'score_differential_norm', 'prev2_yards_gained', 'hb_to_lb_ratio', 'prev2_wpa', 'off_wr_count', 'ep_game_sec_ratio', 'week', 'prev4_yards_gained', 'off_te_count', 'remain_yds_div_score_diff', 'remaining_yards_per_down', 'wr_to_db_ratio', 'def_dl_count', 'quarter_seconds_remaining', 'run_ratio_def_priors', 'prev3_wpa', 'remain_yds_prod_def_dl_count', 'safety_prob', 'game_humidity', 'remain_yds_div_def_dl_count', 'ep_half_sec_ratio', 'def_db_count', 'off_rb_count', 'td_prob', 'remain_yds_prod_def_db_count', 'fg_prob', 'game_temp', 'remain_yds_prod_def_box', 'posteam_timeouts_remaining', 'half_seconds_prod_score_diff', 'run_ratio_off_priors', 'remain_yds_prod_off_hb_count', 'n_offense', 'ol_to_dl_ratio', 'prev1_yards_gained', 'drive_play_count', 'spread_line', 'posteam_score', 'game_wind', 'remain_yds_div_def_box', 'half_seconds_remaining', 'prev3_yards_gained', 'prev1_wpa', 'prev4_wpa']\n",
      " \n",
      "categorical features: 16 : ['posteam', 'posteam_type', 'defteam', 'roof', 'surface', 'offense_formation', 'offense_personnel', 'defense_personnel', 'game_weather', 'play_type_prev1', 'play_type_prev2', 'play_type_prev3', 'play_type_prev4', 'drive_start', 'posteam_season', 'defteam_season']\n",
      " \n",
      "feature count: 155\n"
     ]
    }
   ],
   "source": [
    "# Create feature type lists for column transform stage of the pipeline\n",
    "ordinal_features = X_train.columns[X_train.isin([1,2,3,4,5]).all()].tolist()\n",
    "categorical_features = list(X_train.select_dtypes(include='object'))\n",
    "boolean_features = X_train.columns[X_train.isin([0, 1]).all()].tolist()\n",
    "numeric_features = list(set(X_train.columns) - set(ordinal_features) - set(categorical_features) - set(boolean_features))\n",
    "\n",
    "#print('categorical features:', len(categorical_features), ':', categorical_features)\n",
    "print('ordinal features:', len(ordinal_features), ':', ordinal_features)\n",
    "print(' ')\n",
    "print('boolean features:', len(boolean_features), ':', boolean_features)\n",
    "print(' ')\n",
    "print('numeric features:', len(numeric_features), ':', numeric_features)\n",
    "print(' ')\n",
    "print('categorical features:', len(categorical_features), ':', categorical_features)\n",
    "print(' ')\n",
    "print('feature count:', len(initial_features))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:25.085793Z",
     "start_time": "2023-12-24T15:46:23.482815Z"
    }
   },
   "id": "e95804b4c341fcbb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Custom transformer for IQR outlier exclusion\n",
    "class IQRTransformer:\n",
    "    def __init__(self, numerical_cols):\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            # Calculate the IQR for each numerical column\n",
    "            q1 = X[self.numerical_cols].quantile(0.25)\n",
    "            q3 = X[self.numerical_cols].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "\n",
    "            # Define the lower and upper bounds for outliers\n",
    "            self.lower_bound = (q1 - 1.5 * iqr).to_dict()\n",
    "            self.upper_bound = (q3 + 1.5 * iqr).to_dict()\n",
    "        else:\n",
    "            # Calculate the IQR for each numerical column\n",
    "            q1 = np.quantile(X[:, :], 0.25, axis=0)\n",
    "            q3 = np.quantile(X[:, :], 0.75, axis=0)\n",
    "            iqr = q3 - q1\n",
    "\n",
    "            # Define the lower and upper bounds for outliers\n",
    "            self.lower_bound = (q1 - 1.5 * iqr).tolist()\n",
    "            self.upper_bound = (q3 + 1.5 * iqr).tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            # Exclude outliers based on the IQR for each numerical column\n",
    "            x_outlier_removed = X.copy()\n",
    "            for col in self.numerical_cols:\n",
    "                if col in self.lower_bound and col in self.upper_bound:\n",
    "                    x_outlier_removed = x_outlier_removed[\n",
    "                        (x_outlier_removed[col] >= self.lower_bound[col]) & (x_outlier_removed[col] <= self.upper_bound[col])\n",
    "                    ].dropna()\n",
    "        else:\n",
    "            # Exclude outliers based on the IQR for each numerical column\n",
    "            x_outlier_removed = X.copy()\n",
    "            for i, col in enumerate(self.numerical_cols):\n",
    "                if col in self.lower_bound and col in self.upper_bound:\n",
    "                    lower_bound = self.lower_bound[col]\n",
    "                    upper_bound = self.upper_bound[col]\n",
    "                    x_outlier_removed = x_outlier_removed[\n",
    "                        (x_outlier_removed[:, i] >= lower_bound) & (x_outlier_removed[:, i] <= upper_bound)\n",
    "                    ].dropna()\n",
    "\n",
    "        return x_outlier_removed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T15:46:25.094725Z",
     "start_time": "2023-12-24T15:46:25.080341Z"
    }
   },
   "id": "716f61f917c8a815"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 1000\n",
      "max_resources_: 2000\n",
      "aggressive_elimination: False\n",
      "factor: 2.0\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1\n",
      "n_resources: 2000\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best performance for RandomForest: 0.715100024455471\n",
      "Best parameters: {'clf__bootstrap': True, 'clf__ccp_alpha': 0.014005353466960604, 'clf__criterion': 'entropy', 'clf__max_depth': 28, 'clf__max_features': 0.20990234040959044, 'clf__max_samples': 0.04479186916690281, 'clf__min_impurity_decrease': 8.815157397413805e-05, 'clf__min_samples_leaf': 0.017554275148930945, 'clf__min_samples_split': 0.028561216885612927, 'clf__min_weight_fraction_leaf': 0.02161128618349815, 'clf__n_jobs': 6, 'clf__oob_score': False, 'clf__random_state': 67, 'clf__warm_start': True, 'select__k': 55, 'clf__n_estimators': 2000}\n",
      " \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      " \n",
      "\n",
      "\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 1000\n",
      "max_resources_: 2000\n",
      "aggressive_elimination: False\n",
      "factor: 2.0\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1\n",
      "n_resources: 2000\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best performance for ExtraTrees: 0.7337883565573868\n",
      "Best parameters: {'clf__bootstrap': False, 'clf__ccp_alpha': 0.005716367508961904, 'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__max_features': 0.7765421480248568, 'clf__max_leaf_nodes': 29, 'clf__min_impurity_decrease': 0.022867736998562926, 'clf__min_samples_leaf': 0.20604705794724654, 'clf__min_samples_split': 0.014947610780366147, 'clf__min_weight_fraction_leaf': 0.16884410119773155, 'clf__n_jobs': 6, 'clf__oob_score': False, 'clf__random_state': 67, 'clf__warm_start': False, 'select__k': 55, 'clf__n_estimators': 2000}\n",
      " \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      " \n",
      "\n",
      "\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 1000\n",
      "max_resources_: 2000\n",
      "aggressive_elimination: False\n",
      "factor: 2.0\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1\n",
      "n_resources: 2000\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best performance for GradientBoosting: 0.7365799972586721\n",
      "Best parameters: {'clf__ccp_alpha': 5.593496816765049e-06, 'clf__criterion': 'friedman_mse', 'clf__learning_rate': 0.004460659254079197, 'clf__loss': 'exponential', 'clf__max_depth': 59, 'clf__max_features': 0.4531920718375533, 'clf__max_leaf_nodes': 41, 'clf__min_impurity_decrease': 6.883261775055951e-08, 'clf__min_samples_leaf': 0.15019248856066603, 'clf__min_samples_split': 0.2418111766892731, 'clf__min_weight_fraction_leaf': 0.3821932278101374, 'clf__n_iter_no_change': 100, 'clf__random_state': 67, 'clf__subsample': 0.9430963341257171, 'clf__tol': 2.347606339495969e-05, 'clf__validation_fraction': 0.061368980136258265, 'clf__warm_start': True, 'select__k': 32, 'clf__n_estimators': 2000}\n",
      " \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      " \n",
      "\n",
      "\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 1000\n",
      "max_resources_: 2000\n",
      "aggressive_elimination: False\n",
      "factor: 2.0\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1\n",
      "n_resources: 2000\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best performance for AdaBoost: 0.7222923664917126\n",
      "Best parameters: {'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.001819567616473989, 'clf__random_state': 67, 'select__k': 25, 'clf__n_estimators': 2000}\n",
      " \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      " \n",
      "\n",
      "\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 1000\n",
      "max_resources_: 2000\n",
      "aggressive_elimination: False\n",
      "factor: 2.0\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1\n",
      "n_resources: 2000\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best performance for XGBoost: 0.7314037827543867\n",
      "Best parameters: {'clf__booster': 'dart', 'clf__eval_metric': 'logloss', 'clf__grow_policy': 'lossguide', 'clf__max_depth': 7, 'clf__objective': 'binary:logistic', 'clf__seed': 67, 'select__k': 47, 'clf__n_estimators': 2000}\n",
      " \n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Specify the transformations per data type\n",
    "num_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "                            ('iqr_outlier', IQRTransformer(numerical_cols=numeric_features)),\n",
    "                            ('scaler', feature_scaler),\n",
    "                           ])\n",
    "\n",
    "cat_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                            ('cat_encoder', LeaveOneOutEncoder(handle_missing='value', handle_unknown='value', sigma=sigma, random_state=67)),\n",
    "                            ])\n",
    "\n",
    "ord_trans = Pipeline(steps=[('simple_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                            ('ordinal_encoder', OrdinalEncoder(categories='auto', handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "                           ])\n",
    "\n",
    "preprocessing = ColumnTransformer(transformers=[('numeric_transform', num_trans, numeric_features),\n",
    "                                                ('categorical_transform', cat_trans, categorical_features),\n",
    "                                                ('ordinal_transform', ord_trans, ordinal_features),\n",
    "                                                ],\n",
    "                                     remainder='passthrough',\n",
    "                                    )\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    ('RandomForest', RandomForestClassifier()),\n",
    "    ('ExtraTrees', ExtraTreesClassifier()),\n",
    "    ('GradientBoosting', GradientBoostingClassifier()),\n",
    "    ('AdaBoost', AdaBoostClassifier()),\n",
    "    ('XGBoost', XGBClassifier()),\n",
    "]\n",
    "\n",
    "# Create and run the pipeline\n",
    "for model_name, model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('select', SelectKBest()),\n",
    "        ('smpl', ADASYN(sampling_strategy='not majority', random_state=67)),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "\n",
    "    params = {}\n",
    "\n",
    "    if model_name == 'RandomForest':\n",
    "        params = {\n",
    "            'select__k': randint(20, 80),\n",
    "            'smpl__n_neighbors': randint(2, 6),                       # Only for sampling_strategy='not majority\n",
    "            'clf__bootstrap': [True],\n",
    "            'clf__ccp_alpha': loguniform(1e-06, 1e-00),               # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "            'clf__criterion': ['entropy','gini'],\n",
    "            'clf__max_depth': randint(5, 50),\n",
    "            'clf__max_features': loguniform(0.10, 0.40), \n",
    "            'clf__min_impurity_decrease': loguniform(1e-05, 1e-02),\n",
    "            'clf__max_samples': loguniform(0.02, 0.30),               # Only for bootstrap=True\n",
    "            'clf__min_samples_leaf': loguniform(0.01, 0.20),\n",
    "            'clf__min_samples_split': loguniform(0.01, 0.20),\n",
    "            'clf__min_weight_fraction_leaf': loguniform(0.01, 0.20),\n",
    "            'clf__oob_score': [False],                                # Only for bootstrap=True\n",
    "            'clf__warm_start': [True, False],\n",
    "            'clf__n_jobs': [6],\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "\n",
    "    elif model_name == 'ExtraTrees':\n",
    "        params = {\n",
    "            'select__k': randint(10, 80),\n",
    "            'smpl__n_neighbors': randint(2, 6),                       # Only for sampling_strategy='not majority\n",
    "            'clf__bootstrap': [True, False],\n",
    "            'clf__ccp_alpha': loguniform(1e-06, 1e-00),               # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "            'clf__criterion': ['gini','entropy'],\n",
    "            'clf__max_depth': randint(5, 50),\n",
    "            'clf__max_features': loguniform(0.50, 0.95),\n",
    "            'clf__max_leaf_nodes': randint(15, 70),\n",
    "            #'clf__max_samples': loguniform(0.10, 0.50),               # Only for bootstrap=True\n",
    "            'clf__min_impurity_decrease': loguniform(1e-05, 1e-01),\n",
    "            'clf__min_samples_leaf': loguniform(0.01, 0.30),\n",
    "            'clf__min_samples_split': loguniform(0.01, 0.15),\n",
    "            'clf__min_weight_fraction_leaf': loguniform(0.05, 0.25),\n",
    "            'clf__oob_score': [False],                                # Only for bootstrap=True\n",
    "            'clf__warm_start': [True, False],\n",
    "            'clf__n_jobs': [6],\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    " \n",
    "    elif model_name == 'GradientBoosting':\n",
    "        params = {\n",
    "            'select__k': randint(5, 50),\n",
    "            'smpl__n_neighbors': randint(2, 6),                       # Only for sampling_strategy='not majority\n",
    "            'clf__criterion': ['friedman_mse'],\n",
    "            'clf__ccp_alpha': loguniform(1e-08, 1e-03),                # cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting\n",
    "            'clf__learning_rate': loguniform(1e-05, 1e-00),\n",
    "            'clf__loss': ['log_loss','exponential'],\n",
    "            'clf__max_depth': randint(25, 80),\n",
    "            'clf__max_features': loguniform(0.20, 0.85), \n",
    "            'clf__max_leaf_nodes': randint(20,60),\n",
    "            'clf__min_weight_fraction_leaf': loguniform(0.30, 0.50),   # Must be <= 0.5\n",
    "            'clf__min_impurity_decrease': loguniform(1e-08, 1e-05),\n",
    "            'clf__min_samples_leaf': loguniform(0.01, 0.25),\n",
    "            'clf__min_samples_split': loguniform(0.10, 0.35),\n",
    "            'clf__n_iter_no_change': [150],\n",
    "            'clf__tol': loguniform(1e-08, 1e-03),\n",
    "            'clf__validation_fraction': loguniform(0.05, 0.15),\n",
    "            'clf__warm_start': [True, False],\n",
    "            'clf__subsample': loguniform(0.85, 1.0),\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "        \n",
    "    elif model_name == 'AdaBoost':\n",
    "        params = {\n",
    "            'select__k': randint(10, 50),\n",
    "            'smpl__n_neighbors': randint(2, 6),                       # Only for sampling_strategy='not majority\n",
    "            'clf__algorithm': ['SAMME','SAMME.R'],\n",
    "            'clf__learning_rate': loguniform(1e-05, 1e-01),\n",
    "            'clf__random_state': [67],\n",
    "        }\n",
    "    \n",
    "    elif model_name == 'XGBoost':\n",
    "        params = {\n",
    "            'select__k': randint(5, 80),\n",
    "            'smpl__n_neighbors': randint(2, 6),                       # Only for sampling_strategy='not majority\n",
    "            'clf__booster': ['gbtree','dart'],\n",
    "            'clf__max_depth': [6], #randint(6, 10),\n",
    "            'clf__grow_policy': ['depthwise','lossguide'],\n",
    "            'clf__objective': ['binary:logistic'],\n",
    "            'clf__eval_metric': ['logloss'],\n",
    "            'clf__seed': [67],\n",
    "        }\n",
    "    \n",
    "    search = HalvingRandomSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=params,\n",
    "        scoring='accuracy',\n",
    "        factor=halving_parameter,\n",
    "        resource='clf__n_estimators',\n",
    "        n_candidates='exhaust',\n",
    "        min_resources=min_resource,\n",
    "        max_resources=max_resource,\n",
    "        aggressive_elimination=False,\n",
    "        return_train_score=True,\n",
    "        refit=True,\n",
    "        cv=n_cross_validation,\n",
    "        n_jobs=6,\n",
    "        random_state=67,\n",
    "        verbose=0,\n",
    "        error_score='raise',\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best performance for {model_name}: {search.best_score_}\")\n",
    "    print(' ')\n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "    # print(f\"Best estimator: {search.best_estimator_}\")\n",
    "    \n",
    "    \n",
    "    print(' ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------------')\n",
    "    print(' ')\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-25T01:11:58.038601Z",
     "start_time": "2023-12-24T15:46:25.096060Z"
    }
   },
   "id": "58cc5161"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HalvingRandomSearchCV runtime: 9.43 hours\n"
     ]
    }
   ],
   "source": [
    "# Calculate workbook processing time in hours\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print('Total HalvingRandomSearchCV runtime:', round(total_time / 3600, 2), 'hours')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T01:11:58.053404Z",
     "start_time": "2023-12-25T01:11:58.044526Z"
    }
   },
   "id": "d7e4b6574bc08686"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T01:11:58.103750Z",
     "start_time": "2023-12-25T01:11:58.053594Z"
    }
   },
   "id": "8b4ac4275dcfbe6"
  }
 ],
 "metadata": {
  "colab": {
   "name": "nfl_offensive_play_classification_v1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
